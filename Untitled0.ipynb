{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nidhi2215/Fruits/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is made using the official object detection API documentation using Tensorflow.\n"
      ],
      "metadata": {
        "id": "Sj45Is6SsmDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook focuses on custom object detection and making a bounding box around the object which in this case is a 'car'.\n"
      ],
      "metadata": {
        "id": "xgmwFz-C0IG4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPQyQwqF9shf",
        "outputId": "61a09896-a48a-4622-b1da-64458750ca6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.9.2 in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.50.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (2.9.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (2.0.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (0.27.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (21.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (2.9.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.9.2) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.9.2) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.9.2) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.9.2\n",
        "import tensorflow as tf        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydKWvKhY92UY",
        "outputId": "5d164922-90e6-419b-e54d-b87bb3e677d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)          #to check the version of tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t1nZixsT92Q9",
        "outputId": "35019ba1-4b4b-4191-e68f-6f86ad4bbc87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.50.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.27.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.10.26 which is incompatible.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.10.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.10.1 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow-gpu     #GPU for faster processing and more computation power than CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRktcdWg92OV",
        "outputId": "4ffe019a-f93e-487e-853f-112bcbd15e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 78535, done.\u001b[K\n",
            "remote: Counting objects: 100% (338/338), done.\u001b[K\n",
            "remote: Compressing objects: 100% (196/196), done.\u001b[K\n",
            "remote: Total 78535 (delta 163), reused 286 (delta 141), pack-reused 78197\u001b[K\n",
            "Receiving objects: 100% (78535/78535), 593.71 MiB | 23.99 MiB/s, done.\n",
            "Resolving deltas: 100% (55769/55769), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git       #cloning the official tensorflow repo from github for the setup of object detection\n",
        "                                                          #cloning TFOD 2.0 github."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UutvUV8p92Ls",
        "outputId": "6d611c0e-cc18-4788-b665-f90172ab83c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pwd    #the current directory in which you are working is displayed through 'pwd' command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzPpbfH792I9",
        "outputId": "be45d2fd-67b8-4fe8-db6e-727089065b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "cd /content/models/research   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cFd1gNG292GO",
        "outputId": "c70802d0-3974-48a0-f1d1-c0346a17e15d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here protobuf installation is taking place. Tensorflow object detection uses protobuf libraries  to configure model and training parameters. Also it is being installed in research folder in models.this is also a bash command."
      ],
      "metadata": {
        "id": "CoHGK6qZfWMy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Be0r-PTs92D3"
      },
      "outputs": [],
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGsULZE-92BT",
        "outputId": "d129c9a8-033e-4fa8-98f9-ea9088137ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 25.60 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git   #this is done for cloning  cocoAPI which is one of the dependencies of the tensorflow object detection API."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change current directory to 'cocoapi/PythonAPI'."
      ],
      "metadata": {
        "id": "7Ropkdy2fgil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQDN9EVa91-s",
        "outputId": "7106c418-073e-4207-94d9-25b9718359b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ]
        }
      ],
      "source": [
        "cd cocoapi/PythonAPI     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7MoihWF917-",
        "outputId": "2756c00e-dfff-44fc-8776-be678ddf6ab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ],
      "source": [
        "!make    #for compilation of cocoapi we use 'make' function. !make is a bash command "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is done to copy entire directories by using the recursive flag. Here 'pycocotools' directory is being copied into '/content/models/research'."
      ],
      "metadata": {
        "id": "jLprEkPDUX06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r pycocotools /content/models/research  "
      ],
      "metadata": {
        "id": "nsFdbywXU218"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to reach the research folder of models directory. (Move a level up)"
      ],
      "metadata": {
        "id": "99Rm0PhpUeVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2tlKyOcB---h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef58a929-11a6-4a4f-fc6a-8e2ecb5a6f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/cocoapi\n"
          ]
        }
      ],
      "source": [
        "cd ..   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to reach the research folder of models directory , we use this command.  (Move a level up)"
      ],
      "metadata": {
        "id": "IJ6jSKBNUlDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiSva0p9912t",
        "outputId": "0b4931a1-e077-45fc-9a50-2cb5331e2276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "cd ..   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "       <!-- #Installation of the Object Detection API is achieved by installing the object_detection package. -->"
      ],
      "metadata": {
        "id": "OuIaImd3eZzj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gBprjJ_k910A"
      },
      "outputs": [],
      "source": [
        "cp object_detection/packages/tf2/setup.py .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <!-- #These command are run within 'Tensorflow\\models\\research'. -->"
      ],
      "metadata": {
        "id": "EU-_BQ9eeekH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install .                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN4wb8THUEgm",
        "outputId": "f79d1a07-e7fd-44e2-d71b-f0acac7455a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 61.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.5)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 47.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.0 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 45.3 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.8 MB/s \n",
            "\u001b[?25hCollecting immutabledict\n",
            "  Downloading immutabledict-2.2.2-py3-none-any.whl (4.0 kB)\n",
            "Collecting tensorflow~=2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 57.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow-text~=2.10.0\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 40.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.5)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Collecting keras\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 60.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "\u001b[K     |████████████████████████████████| 506 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 51.2 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting cloudpickle~=2.1.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 62.2 MB/s \n",
            "\u001b[?25hCollecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.8.0)\n",
            "Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696451 sha256=07363a6301424efd96f105574ab67210e8f0b1c96e3d43118fe8b973d50b2daf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yjkfu72y/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=2569a62772b1895f33e46046b4a1b48a326f85e91694a5f735896da007293a11\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=283fe3f18f679d9a19bd25008e1f2ac7c627035928353d2dc81cae1603f9f87c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=7c1ac2fc2e0a1f32b681682e2511965ee3cbbd4a2eaab37a360f884543a0ffcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=62d70af6d90656c0fcc0d294fdc8acf35d8186f21aa091d3451dd19adf1501cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection dill avro-python3 docopt seqeval\n",
            "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0\n",
            "    Uninstalling PyYAML-6.0:\n",
            "      Successfully uninstalled PyYAML-6.0\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.2\n",
            "    Uninstalling pymongo-4.3.2:\n",
            "      Successfully uninstalled pymongo-4.3.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.0 flatbuffers-22.10.26 hdfs-2.7.0 immutabledict-2.2.2 keras-2.10.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.1 portalocker-2.6.0 proto-plus-1.22.1 protobuf-3.19.6 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <!-- #this is done to test the installation of object_detection package. -->"
      ],
      "metadata": {
        "id": "tNFwn_dbeHYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From within TensorFlow/models/research/. this is done to test the installation of object_detection package."
      ],
      "metadata": {
        "id": "diLu6Ok0eOlb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V42Ymeei91ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7849eb41-6fd3-456d-c5ad-aa537060c3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-06 07:30:28.010085: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-06 07:30:32.458020: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Running tests under Python 3.7.15: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W1106 07:30:32.977135 139951475369856 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.82s\n",
            "I1106 07:30:33.277923 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.82s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n",
            "I1106 07:30:33.959351 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.32s\n",
            "I1106 07:30:34.279632 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.32s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.49s\n",
            "I1106 07:30:34.766373 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.49s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.17s\n",
            "I1106 07:30:39.933252 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 5.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1106 07:30:39.948322 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.1s\n",
            "I1106 07:30:40.049159 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "I1106 07:30:40.087470 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
            "I1106 07:30:40.142187 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.28s\n",
            "I1106 07:30:40.429329 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.24s\n",
            "I1106 07:30:40.672276 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.22s\n",
            "I1106 07:30:40.895782 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.27s\n",
            "I1106 07:30:41.163380 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.26s\n",
            "I1106 07:30:41.420961 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.26s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.09s\n",
            "I1106 07:30:41.515041 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1106 07:30:41.970465 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1106 07:30:41.970735 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n",
            "I1106 07:30:41.970836 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 3\n",
            "I1106 07:30:41.977076 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:42.048768 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:42.049140 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:42.288128 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:42.288389 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:42.773198 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:42.773476 139951475369856 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1106 07:30:43.456826 139951475369856 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1106 07:30:43.457108 139951475369856 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1106 07:30:44.558750 139951475369856 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1106 07:30:44.559012 139951475369856 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1106 07:30:45.810624 139951475369856 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1106 07:30:45.813516 139951475369856 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1106 07:30:46.898856 139951475369856 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1106 07:30:46.899132 139951475369856 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1106 07:30:47.133511 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1106 07:30:47.325225 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:30:47.516824 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1106 07:30:47.517081 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n",
            "I1106 07:30:47.517184 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 4\n",
            "I1106 07:30:47.520439 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:47.575731 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:47.575971 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:47.902998 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:47.903251 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:48.613814 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:48.614061 139951475369856 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1106 07:30:49.470277 139951475369856 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1106 07:30:49.470535 139951475369856 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1106 07:30:50.511997 139951475369856 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1106 07:30:50.512262 139951475369856 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1106 07:30:51.534860 139951475369856 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1106 07:30:51.535153 139951475369856 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1106 07:30:52.531409 139951475369856 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1106 07:30:52.531623 139951475369856 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1106 07:30:52.861186 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1106 07:30:52.944083 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:30:53.023161 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1106 07:30:53.023374 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n",
            "I1106 07:30:53.023440 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 5\n",
            "I1106 07:30:53.025391 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:53.048200 139951475369856 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1106 07:30:53.048404 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:53.237805 139951475369856 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1106 07:30:53.238003 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:53.578971 139951475369856 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1106 07:30:53.579192 139951475369856 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1106 07:30:53.994020 139951475369856 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1106 07:30:53.994220 139951475369856 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1106 07:30:54.534177 139951475369856 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1106 07:30:54.534425 139951475369856 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1106 07:30:55.096955 139951475369856 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1106 07:30:55.097161 139951475369856 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1106 07:30:55.836923 139951475369856 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1106 07:30:55.837123 139951475369856 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1106 07:30:56.180176 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1106 07:30:56.267768 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:30:56.344143 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1106 07:30:56.344379 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n",
            "I1106 07:30:56.344472 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 6\n",
            "I1106 07:30:56.346494 139951475369856 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1106 07:30:56.373936 139951475369856 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1106 07:30:56.374152 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:30:56.592222 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:30:56.592489 139951475369856 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1106 07:30:56.973472 139951475369856 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1106 07:30:56.973689 139951475369856 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1106 07:30:57.632094 139951475369856 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1106 07:30:57.632299 139951475369856 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1106 07:30:58.289131 139951475369856 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1106 07:30:58.289434 139951475369856 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1106 07:30:59.028917 139951475369856 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1106 07:30:59.029186 139951475369856 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1106 07:30:59.970773 139951475369856 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1106 07:30:59.971041 139951475369856 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1106 07:31:00.337251 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1106 07:31:00.421411 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:31:00.500756 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1106 07:31:00.500950 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n",
            "I1106 07:31:00.501010 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1106 07:31:00.502887 139951475369856 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1106 07:31:00.526552 139951475369856 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1106 07:31:00.526742 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:31:00.727075 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:31:00.727291 139951475369856 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1106 07:31:01.204804 139951475369856 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1106 07:31:01.205019 139951475369856 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1106 07:31:01.712545 139951475369856 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1106 07:31:01.712761 139951475369856 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1106 07:31:02.494735 139951475369856 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1106 07:31:02.495128 139951475369856 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1106 07:31:03.280038 139951475369856 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1106 07:31:03.280235 139951475369856 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1106 07:31:04.475695 139951475369856 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1106 07:31:04.475910 139951475369856 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1106 07:31:04.838510 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1106 07:31:04.926469 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:31:05.020364 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1106 07:31:05.020568 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n",
            "I1106 07:31:05.020651 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 7\n",
            "I1106 07:31:05.022626 139951475369856 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1106 07:31:05.045442 139951475369856 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1106 07:31:05.045630 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:31:05.331883 139951475369856 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1106 07:31:05.332080 139951475369856 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1106 07:31:05.910771 139951475369856 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1106 07:31:05.910981 139951475369856 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1106 07:31:06.508213 139951475369856 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1106 07:31:06.508428 139951475369856 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1106 07:31:07.653645 139951475369856 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1106 07:31:07.653852 139951475369856 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1106 07:31:08.590713 139951475369856 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1106 07:31:08.590916 139951475369856 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1106 07:31:10.035300 139951475369856 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1106 07:31:10.035570 139951475369856 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1106 07:31:10.668607 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1106 07:31:10.774999 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:31:10.884849 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1106 07:31:10.885094 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1106 07:31:10.885155 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1106 07:31:10.887084 139951475369856 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1106 07:31:10.911574 139951475369856 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1106 07:31:10.911811 139951475369856 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1106 07:31:11.194360 139951475369856 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1106 07:31:11.194603 139951475369856 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1106 07:31:11.954065 139951475369856 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1106 07:31:11.954260 139951475369856 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1106 07:31:12.749195 139951475369856 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1106 07:31:12.749415 139951475369856 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1106 07:31:13.776269 139951475369856 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1106 07:31:13.776492 139951475369856 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1106 07:31:14.855389 139951475369856 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1106 07:31:14.855600 139951475369856 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1106 07:31:16.684370 139951475369856 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1106 07:31:16.684587 139951475369856 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1106 07:31:17.373546 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1106 07:31:17.488137 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 07:31:17.615011 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1106 07:31:17.615208 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n",
            "I1106 07:31:17.615269 139951475369856 ssd_efficientnet_bifpn_feature_extractor.py:154] EfficientDet BiFPN num iterations: 8\n",
            "I1106 07:31:17.617110 139951475369856 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1106 07:31:17.640733 139951475369856 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1106 07:31:17.640935 139951475369856 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1106 07:31:18.029505 139951475369856 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1106 07:31:18.029710 139951475369856 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1106 07:31:19.299385 139951475369856 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1106 07:31:19.299648 139951475369856 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1106 07:31:20.216347 139951475369856 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1106 07:31:20.216600 139951475369856 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1106 07:31:21.589026 139951475369856 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1106 07:31:21.589264 139951475369856 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1106 07:31:23.090640 139951475369856 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1106 07:31:23.090857 139951475369856 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1106 07:31:25.464719 139951475369856 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1106 07:31:25.464929 139951475369856 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1106 07:31:26.494220 139951475369856 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1106 07:31:26.614288 139951475369856 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 45.27s\n",
            "I1106 07:31:26.784211 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 45.27s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1106 07:31:26.828416 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1106 07:31:26.830852 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1106 07:31:26.831599 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1106 07:31:26.833697 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1106 07:31:26.835507 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1106 07:31:26.836076 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1106 07:31:26.837425 139951475369856 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 54.376s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python object_detection/builders/model_builder_tf2_test.py          "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xzM3zlsMPwQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "    training_demo is a folder which we have created .It is temporary as it gets recycled once the runtime of notebook is deleted. \n",
        "    training_demo has 5 folders:\n",
        "    1.annotations: In the beginning it only contains label_map.pbtxt.\n",
        "      Structure of label_map.pbtxt: item {\n",
        "                                            id: 1\n",
        "                                            name: 'car'\n",
        "                                         }\n",
        "      TensorFlow requires a label map, which namely maps each of the used labels to an integer values. This label map is used both by the training and detection processes.\n",
        "    2.images:For annotating the images we have used labelaiMG. It has 2 folders:-\n",
        "      a)train- Contains images (in jpeg format) for training the model and their associated xml (annotation) files (with label).\n",
        "      b)test- Contains images for testing and their associated xml files.\n",
        "    3.exported_models: This folder will initially remain empty but will later on (after executing some commands) will contain our final model once it is trained.\n",
        "    4.models\n",
        "    5.pre-trained-models\n",
        "\n",
        "'''\n",
        "\n",
        "'''\n",
        "    training_demo has 4 files which were all given in the documentation.\n",
        "    1.model_main_tf2\n",
        "    2.exporter_main_t2\n",
        "    3.export_tflite_graph_tf2\n",
        "    4.generate tfrecord.py \n",
        "    \n",
        "'''"
      ],
      "metadata": {
        "id": "_yZLK65KAElc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc197f03-0b7b-4f16-e064-c9ce91d480a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    training_demo has 4 files which were all given in the documentation.\\n    1.model_main_tf2\\n    2.exporter_main_t2\\n    3.export_tflite_graph_tf2\\n    4.generate tfrecord.py \\n    \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <!-- #changing directory to '/content/training_demo/pre-trained-models'\n",
        "                                                  #pre-trained-models contains our ssd resnet 101 v1 fpn 640x640 model. (This is an example of transer learning as we are using a pretrained model for our object detection task) -->"
      ],
      "metadata": {
        "id": "mLMhGMvae55o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " changing directory to '/content/training_demo/pre-trained-models'.\n",
        "                                                  pre-trained-models contains our ssd resnet 101 v1 fpn 640x640 model. (This is an example of transer learning as we are using a pretrained model for our object detection task)"
      ],
      "metadata": {
        "id": "DegjJRVNfBGs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj4lcCEf91rp",
        "outputId": "098a2d74-c9f5-435f-e707-026d0947aafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_demo/pre-trained-models\n"
          ]
        }
      ],
      "source": [
        "cd /content/training_demo/pre-trained-models     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are trying to get 'ssd resnet 101 v1 fpn 640x640 model' from **tensorflow model zoo** in 'pre-trained-models' directory."
      ],
      "metadata": {
        "id": "sc05p1mHGqnV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-stYe2f91pO",
        "outputId": "fbd471a6-7c4f-4369-8914-cde84fa036e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-06 07:31:57--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.120.128, 2607:f8b0:4001:c18::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.120.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 386527459 (369M) [application/x-tar]\n",
            "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_resnet101_v1_fp 100%[===================>] 368.62M   194MB/s    in 1.9s    \n",
            "\n",
            "2022-11-06 07:31:59 (194 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#This will directly download the zip file in our pre-trained-models directory\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmoJbFkl91mu",
        "outputId": "457ac103-0b28-451d-9a5e-c84968150487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "#for extraction of zip file.\n",
        "!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now this is the structure of our pre-trained-models\n"
      ],
      "metadata": {
        "id": "ibJULdrIRvnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "67bNtbNZRkwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**CREATE TENSORFLOW RECORDS**"
      ],
      "metadata": {
        "id": "nrazgG_ePQXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "25mElcCG91j_",
        "outputId": "627a6c46-9eee-49c2-bc4a-dc759521a451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_demo/pre-trained-models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V_DQJ-xBBQ-",
        "outputId": "de513f5f-c212-41cf-a18e-6f8c71e188f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/training_demo\n"
          ]
        }
      ],
      "source": [
        "cd /content/training_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enKZezA2BCJQ",
        "outputId": "17a6b770-135c-4b33-9c75-9310ab07f083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  \u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mexported-models\u001b[0m/     \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n",
            "exporter_main_v2.py  model_main_tf2.py\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are converting our xml files(mainly our bounding box coordinates) into tfrecord files using generate_tfrecord.py so that it is understandable by the training model."
      ],
      "metadata": {
        "id": "XHZ0SnnCP0h_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- #Here \"/content/training_demo/images/train\" is the PATH_TO_IMAGES_FOLDER for train.\n",
        "#Here \"/content/training_demo/annotations/train.record\" is the path to annotation folder in taining_demo. -->"
      ],
      "metadata": {
        "id": "q59jt5qUcqY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQGtBG_FBQlt",
        "outputId": "2d8a6052-4283-4b61-d1a9-5cddcd3ed93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-06 07:34:37.829245: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-06 07:34:41.421255: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n"
          ]
        }
      ],
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H10eMTCEfeK7",
        "outputId": "26ea9873-0cd8-4302-8790-fc0b5236fe44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-06 07:34:44.538885: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-06 07:34:47.336523: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Now we have created a folder \"my_ssd_resnet101_v1_fpn\" inside models directory and copy the pipeline.config file from pre-trained models to folder \"my_ssd_resnet101_v1_fpn\".\n",
        "Some changes that are made to the pipeline config: \n",
        "1. No. of classes: 1  \n",
        "2. Batch Size: 4       \n",
        "3. No. of steps: 2000\n",
        "4. Fine_tune_checkpoint_type: \"detection\"\n",
        "5. use_bfloat16: false   (As we are using GPU instead of TPU)\n",
        "6. fine_tune_checkpoint\n",
        "7. path to label_map.pbtxt\n",
        "8. path of test.record\n",
        "9. path of train.record.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "INkS50SSTXcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n-VKdIJgBQig",
        "outputId": "fddd180c-14d2-4e4c-b8b6-f22830ceefdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_demo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xofXWS_9BQf1",
        "outputId": "c68bacec-2c4f-4164-e9b9-b5d8a1a047ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported-models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls   #to list all the folders/files in the current path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training of our model using weights**"
      ],
      "metadata": {
        "id": "d3evcAVObEqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config  #Here we are performing transer learning using ssd_resnet101_v1_fpn_640x640."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oqqOjwnn-NP",
        "outputId": "51b62bc4-3bdb-4b8d-cfdc-ebd140920815"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-06 07:45:08.419261: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-06 07:45:18.237177: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W1106 07:45:18.262200 140415872382848 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I1106 07:45:18.365958 140415872382848 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I1106 07:45:18.372843 140415872382848 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1106 07:45:18.373127 140415872382848 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1106 07:45:18.420962 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "I1106 07:45:18.444443 140415872382848 dataset_builder.py:162] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "I1106 07:45:18.448453 140415872382848 dataset_builder.py:79] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1106 07:45:18.448693 140415872382848 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1106 07:45:18.448761 140415872382848 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1106 07:45:18.464023 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1106 07:45:18.503491 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1106 07:45:26.850872 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1106 07:45:30.577850 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1106 07:45:32.807562 140415872382848 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1106 07:46:52.344413 140413383575296 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Clihu3YCBQa3",
        "outputId": "b29abbce-3363-4b08-9c4b-75079e59951c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_demo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting the model in 'exported_models'"
      ],
      "metadata": {
        "id": "yniAOKahoAB3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ulhs0kjtBQYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b673b2-1424-4f97-be0d-1438b2f63933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-06 07:01:39.232186: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-06 07:01:40.918126: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-06 07:01:40.918322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2022-11-06 07:01:40.918354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-11-06 07:01:45.599210: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W1106 07:01:45.881407 139890070165376 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f39ca1d1b10>, because it is not built.\n",
            "W1106 07:02:09.845609 139890070165376 save_impl.py:68] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f39ca1d1b10>, because it is not built.\n",
            "W1106 07:02:44.112879 139890070165376 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "I1106 07:02:54.738986 139890070165376 builder_impl.py:780] Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n",
            "I1106 07:02:56.148268 139890070165376 config_util.py:254] Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_demo/exported_models/my_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# folder path\n",
        "dir_path = r'/content/training_demo/images/test'\n",
        "count = 0\n",
        "# Iterate directory\n",
        "for path in os.listdir(dir_path):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(dir_path, path)):\n",
        "        count += 1\n",
        "print('File count:', count)\n",
        "#So the total no. of images with their associated annotation file = count//2 as there is a pair of image and xml file .\n",
        "Number=count//2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTeuOSNlzXgV",
        "outputId": "48f2a5d3-6719-4e31-ad8d-1c2f9e03914d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File count: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inferencing my model\n"
      ],
      "metadata": {
        "id": "H85DTbYpoHZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ybpzbAIGBQVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "6c62f4cd-9f98-4266-e7d8-35d0f35a82e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b761a242328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1) . Here logging is done to detect the cause of problem if in case the program crashes. Logger keeps the track of events that are occuring.\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse      # argparse is the command-line parsing module in  Python.\n",
        "from google.colab.patches import cv2_imshow   #for viewing of images.\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# path to image directory\n",
        "IMAGE_PATHS = '/content/training_demo/images/train/imagei.jpg'\n",
        "\n",
        "\n",
        "# path to model directory\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
        "\n",
        "# path to label map\n",
        "PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# minimum confidence threshold which is the certainity related to each discovered pattern.\n",
        "MIN_CONF_THRESH = float(0.60)   \n",
        "\n",
        "# Loading the model.\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()     #The time() function returns the number of seconds passed since epoch.It returns a float type value.\n",
        "                            # Here start time is the timestamp at the beginning of the code start using time().\n",
        "\n",
        "# Load saved model and build detection model.\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()   # Here end time is the timestamp at the end of the code end.\n",
        "elapsed_time = end_time - start_time  #time elapsed in executing a code\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# Loading label map data for plotting\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,Number):\n",
        "  print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "  image = cv2.imread(IMAGE_PATHS)\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  # input_tensor = np.expand_dims(image_np, 0)\n",
        "  detections = detect_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "  \n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxKvnehiBQTQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "IMAGE_PATHS = '/content/training_demo/images/train/image9.jpg'\n",
        "\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "image = cv2.imread(IMAGE_PATHS)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "input_tensor = tf.convert_to_tensor(image)\n",
        "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "# input_tensor = np.expand_dims(image_np, 0)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "# All outputs are batches tensors.\n",
        "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "# We're only interested in the first num_detections.\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "               for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "image_with_detections = image.copy()\n",
        "\n",
        "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_with_detections,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=0.5,\n",
        "      agnostic_mode=False)\n",
        "print('Done')\n",
        "# DISPLAYS OUTPUT IMAGE\n",
        "cv2_imshow(image_with_detections)\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNtXQsn2BQOH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oQtHjMLBQLK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaRcjEdBBQI7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6uy-l1RBQGp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N5RpmNFBQEV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCpbWibmBQCS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvQwK34_BP_c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcskJ_TYBP9X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy8Ah1TtBP61"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3n154qKBP4V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyLG7UkRBP17"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWDBGswTKlDoQJm6cgU90N",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}